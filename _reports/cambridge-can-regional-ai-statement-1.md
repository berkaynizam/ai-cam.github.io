---
title: "Public dialogue on AI in local government: Interim Results"
excerpt: "In November 2025, ai@cam worked with Hopkins Van Mil to convene public
  dialogues with 95 Cambridgeshire residents to explore their expectations,
  hopes, and concerns regarding the use of AI in local government. This interim
  report explores the findings from that first phase. The dialogue reveals
  cautious optimism: residents recognise the substantial potential for AI to
  enhance service delivery, and emphasise that its adoption must adhere to
  defined safeguards."
report_date: 2025-12-09
tags:
  - tag: Policy Brief
cover_image: /assets/images/uploads/summary-report-image-2.png
abstract: >-
  In November 2025, ai@cam worked with Hopkins Van Mil to convene public
  dialogues with 95 Cambridgeshire residents to explore their expectations,
  hopes, and concerns regarding the use of AI in local government. This interim
  report explores the findings from that first phase. The dialogue reveals
  cautious optimism: residents recognise the substantial potential for AI to
  enhance service delivery, and emphasise that its adoption must adhere to
  defined safeguards.


  Participants emphasise that AI should generate demonstrable improvements in people’s lives rather than serve primarily as a cost-saving mechanism. They expect AI to enhance, not replace, human roles - automating routine tasks so staff can focus on empathy, creativity and nuanced judgment.
links:
  - link: https://www.ai.cam.ac.uk/assets/uploads/interim-report-public-dialogue-on-ai-in-local-government.pdf
    link_text: Download full report
authors: []
content: >-
  ### Executive Summary


  ai@cam is the University of Cambridge’s mission to create AI innovations that serve science, citizens, and society. Our first year of operations has established the initiative as an incubator for interdisciplinary AI addressing real-world needs.


  ### Key Recommendations


  * Holistically examine the impact GenAI is having on the workforce in the creative industries, including by commissioning research on AI adoption across the sector, and use it to inform robust policies for supporting the sector’s workforce.

  * Encourage the uptake of licensing agreements to ensure copyright holders are compensated for use of their work by AI systems, but it should also ensure that these licensing agreements fully acknowledge the rights of copyright holders and fairly compensate them for the use of their works.

  * Independently ratify and adopt the Beijing Treaty on Audiovisual Performances as a first step in ensuring greater protections on performers’ rights and from false attribution by AI systems.

  * Adopt transparency requirements on the training of AI systems which include the mandatory disclosure of data provenance.

  * Clarify that only a human author will be afforded copyright in the outputs generated by AI models and produce guidance on: a) the threshold for ‘creative intellectual effort’ in achieving copyright in AI outputs; b) the need for recognition and compensation to artists whose name and canon are used in prompts to AI models that generate outputs; and c) measures required to avoid false attribution in AI outputs.

  * We urge caution against embarking on the path of a Text and Data Mining (TDM) exemption, regardless of an ‘opt-out’ mechanism, without a robust economic analysis of the impact that it will have on the creative industries.


  ### Key Achievements 2023-24


  * Launched five ambitious AI-deas research programmes across 19 Departments

  * Supported 46 HPC Pioneer Projects from 20 Departments

  * Generated over £190k in external income

  * Facilitated over 400 engagements with researchers, policymakers and public

  * Established Policy Lab connecting research to national priorities


  ### Progress Against Strategic Objectives


  ###### 1. Research Community Development


  AI-deas initiative launched 5 research programmes across mental health, fertility, public services, language equity, and climate HPC Pioneer Project scheme supported 46 research projects from 20 Departments Over 400 engagements with researchers, policymakers, and partners


  ###### 2. Partnerships and Ethics


  Collaborated with Kavli Centre for Ethics, Science, and the Public Conducted public dialogue workshops and citizen panels Developed policy briefs with Bennett Institute and Minderoo Centre


  ###### 3. Innovation Spaces


  Supported teams in accessing funding opportunities Connected researchers with compute resources Facilitated cross-departmental collaborations


  ###### 4. Knowledge Access


  Developed teaching and learning initiatives Supported early career researcher engagement Built connections with industry partners


  ###### 5. Policy Engagement


  Established Policy Lab connecting research to policy Contributed to AI Safety Summit discussions Engaged with local and national government


  ### Vision for the Future


  The University aspires to be:


  * A global force in AI research

  * A world-leader in education

  * An engine for innovation delivering social benefit


  This vision is built on three pillars:


  1. Growing research capability through cluster hiring

  2. Building world-class compute infrastructure

  3. Creating connections for real-world impact
---
**Key Findings**

* **AI should be deployed only where it delivers clear public benefit.**


  Residents want AI used to address real service pressures, such as heavy administrative workloads or slow processes. Innovation for its own sake, or deployment driven primarily by cost-savings that do not deliver service improvements, will not gain public trust or support.
* **Humans must remain central to all decisions that affect people’s lives.**


  Participants support AI automating routine tasks but are opposed to AI making final decisions, particularly in sensitive areas involving vulnerable individuals. They expect councils to protect existing jobs, invest in staff training, and ensure robust human oversight is built into AI tools from the start.
* **Public trust requires full transparency, clear accountability and evidence that AI works.**


  Residents want to know when AI is used, how it operates, what data it relies on, and who is responsible for it. They expect AI systems to be rigorously tested, reliable, unbiased and independently evaluated before wider adoption.
* **AI systems must be inclusive, accessible and secure for all residents.**


  Participants expect human alternatives to remain available, systems that work for people with different levels of digital literacy, robust protections of personal data and strong safeguards against system failure or malicious attack.
* **Residents expect to play an active role in shaping how AI is developed and deployed.**


  Participants want meaningful involvement throughout the process, from setting priorities to designing, testing and monitoring AI systems. They also expect councils to consider broader implications, including environmental impacts, data security, future workforce skills and alignment with wider public service goals.

**Impact and Next Steps**

The findings from this interim report are shaping the direction of our [Local Government AI Accelerator](https://www.ai.cam.ac.uk/calls/local-government-ai-accelerator), and we encourage applicants to draw on these insights when developing their proposals. This can include consideration of:

* Decision-making boundaries: Is AI making recommendations that humans review, or final decisions that directly affect people’s lives? If the latter, how will meaningful human oversight be ensured? 
* Transparency and consent: How will residents know when AI is being used in their interactions with the council? What information will they receive about how it works and what data it uses? 
* Accessibility and inclusion: How will the solution work for residents who are digitally excluded, have disabilities, speak English as a second language, or face other barriers? 
* Workforce impact: How will this affect council staff roles and skills? What training or support will be needed? 
* Exit and contingency planning: What happens if the AI system fails or needs to be withdrawn? How will services continue? What skills and capabilities need to be maintained?

A second phase of dialogue will take place in March 2026, and insights will continue to inform the programme. The interim public dialogue report can be found [here.](https://www.ai.cam.ac.uk/assets/uploads/interim-report-public-dialogue-on-ai-in-local-government.pdf)



**Key Findings**

* **AI should be deployed only where it delivers clear public benefit.**


  Residents want AI used to address real service pressures, such as heavy administrative workloads or slow processes. Innovation for its own sake, or deployment driven primarily by cost-savings that do not deliver service improvements, will not gain public trust or support.
* **Humans must remain central to all decisions that affect people’s lives.**


  Participants support AI automating routine tasks but are opposed to AI making final decisions, particularly in sensitive areas involving vulnerable individuals. They expect councils to protect existing jobs, invest in staff training, and ensure robust human oversight is built into AI tools from the start.
* **Public trust requires full transparency, clear accountability and evidence that AI works.**


  Residents want to know when AI is used, how it operates, what data it relies on, and who is responsible for it. They expect AI systems to be rigorously tested, reliable, unbiased and independently evaluated before wider adoption.
* **AI systems must be inclusive, accessible and secure for all residents.**


  Participants expect human alternatives to remain available, systems that work for people with different levels of digital literacy, robust protections of personal data and strong safeguards against system failure or malicious attack.
* **Residents expect to play an active role in shaping how AI is developed and deployed.**


  Participants want meaningful involvement throughout the process, from setting priorities to designing, testing and monitoring AI systems. They also expect councils to consider broader implications, including environmental impacts, data security, future workforce skills and alignment with wider public service goals.

**Impact and Next Steps**

The findings from this interim report are shaping the direction of our [Local Government AI Accelerator](https://www.ai.cam.ac.uk/calls/local-government-ai-accelerator), and we encourage applicants to draw on these insights when developing their proposals. This can include consideration of:

* Decision-making boundaries: Is AI making recommendations that humans review, or final decisions that directly affect people’s lives? If the latter, how will meaningful human oversight be ensured? 
* Transparency and consent: How will residents know when AI is being used in their interactions with the council? What information will they receive about how it works and what data it uses? 
* Accessibility and inclusion: How will the solution work for residents who are digitally excluded, have disabilities, speak English as a second language, or face other barriers? 
* Workforce impact: How will this affect council staff roles and skills? What training or support will be needed? 
* Exit and contingency planning: What happens if the AI system fails or needs to be withdrawn? How will services continue? What skills and capabilities need to be maintained?

A second phase of dialogue will take place in March 2026, and insights will continue to inform the programme. The interim public dialogue report can be found [here.](https://www.ai.cam.ac.uk/assets/uploads/interim-report-public-dialogue-on-ai-in-local-government.pdf)

[](https://www.ai.cam.ac.uk/)
